# ============================================================
# NEXA ‚Äî Conversion du mod√®le .pth ‚Üí ONNX ‚Üí TFLite
# √Ä ex√©cuter localement sur ton PC apr√®s t√©l√©chargement du .pth
# ============================================================
# Installation requise :
#   pip install torch torchvision timm onnx onnxruntime
#   pip install onnx-tf tensorflow
# ============================================================
import onnx
import onnxruntime as ort
import torch
import timm
import numpy as np
import os

# ============================================================
# CONFIGURATION ‚Äî Modifie ce chemin selon ton fichier t√©l√©charg√©
# ============================================================
CHEMIN_MODELE = 'modeles/meilleur_modele_fold2.pth'
NOM_ONNX      = 'modeles/nexa_biomasse.onnx'
NOM_MODELE    = 'efficientnet_b2'
TAILLE_IMAGE  = (260, 260)  # Taille d'entr√©e EfficientNet-B2
NOM_TFLITE    = 'nexa_biomasse.tflite'

# ============================================================
# √âTAPE 1 ‚Äî Chargement du mod√®le PyTorch
# ============================================================
print("üìÇ Chargement du mod√®le PyTorch...")

model = timm.create_model(NOM_MODELE, pretrained=False, num_classes=3)
model.load_state_dict(
    torch.load(CHEMIN_MODELE, map_location='cpu', weights_only=True)
)
model.eval()
print(f"‚úÖ Mod√®le charg√© : {CHEMIN_MODELE}")

# ============================================================
# √âTAPE 2 ‚Äî Test rapide : v√©rifier que le mod√®le tourne
# ============================================================
print("\nüß™ Test du mod√®le sur une image factice...")
image_factice = torch.randn(1, 3, TAILLE_IMAGE[0], TAILLE_IMAGE[1])
with torch.no_grad():
    sortie = model(image_factice)

print(f"‚úÖ Sortie du mod√®le : {sortie.numpy()}")
print(f"   ‚Üí Green: {sortie[0][0]:.2f}g | Clover: {sortie[0][1]:.2f}g | Dead: {sortie[0][2]:.2f}g")
gdm   = sortie[0][0].item() + sortie[0][1].item()
total = gdm + sortie[0][2].item()
print(f"   ‚Üí GDM: {gdm:.2f}g | Total: {total:.2f}g")

# ============================================================
# √âTAPE 3 ‚Äî Export vers ONNX
# ============================================================
print(f"\nüì¶ Export vers ONNX ‚Üí {NOM_ONNX}")

torch.onnx.export(
    model,
    image_factice,
    NOM_ONNX,
    input_names=["image"],
    output_names=["biomasse"],
    dynamic_axes={
        "image":    {0: "batch_size"},
        "biomasse": {0: "batch_size"}
    },
    opset_version=11,
    export_params=True,
    do_constant_folding=True,  # Optimisation du graphe
)
print(f"‚úÖ Fichier ONNX g√©n√©r√© : {NOM_ONNX} ({os.path.getsize(NOM_ONNX) / 1e6:.1f} MB)")

# ============================================================
# √âTAPE 4 ‚Äî Validation du mod√®le ONNX
# ============================================================
print("\nüîç Validation du mod√®le ONNX...")

modele_onnx = onnx.load(NOM_ONNX)
onnx.checker.check_model(modele_onnx)
print("‚úÖ Mod√®le ONNX valide")

# Test d'inf√©rence ONNX

session = ort.InferenceSession(NOM_ONNX)
entree = {session.get_inputs()[0].name: image_factice.numpy()}
sortie_onnx = session.run(None, entree)[0]
print(f"‚úÖ Inf√©rence ONNX OK : {sortie_onnx}")

# V√©rification coh√©rence PyTorch vs ONNX
diff = np.abs(sortie.numpy() - sortie_onnx).max()
print(f"   Diff√©rence max PyTorch vs ONNX : {diff:.6f} (doit √™tre < 0.001)")
assert diff < 0.01, f"‚ö†Ô∏è Diff√©rence trop grande : {diff}"

# ============================================================
# √âTAPE 5 ‚Äî Conversion ONNX ‚Üí TFLite
# ============================================================
print(f"\nüì± Conversion vers TFLite ‚Üí {NOM_TFLITE}")
print("(Cette √©tape peut prendre 2-5 minutes...)")

try:
    # M√©thode recommand√©e via onnx-tf
    from onnx_tf.backend import prepare
    import tensorflow as tf

    # ONNX ‚Üí TensorFlow SavedModel
    DOSSIER_TF = 'nexa_biomasse_tf_savedmodel'
    print("  ‚Üí Conversion ONNX vers TensorFlow SavedModel...")
    tf_rep = prepare(modele_onnx)
    tf_rep.export_graph(DOSSIER_TF)
    print(f"  ‚úÖ SavedModel TF g√©n√©r√© dans : {DOSSIER_TF}/")

    # TensorFlow SavedModel ‚Üí TFLite
    print("  ‚Üí Conversion SavedModel vers TFLite...")
    converter = tf.lite.TFLiteConverter.from_saved_model(DOSSIER_TF)

    # Optimisation pour mobile (r√©duit la taille du mod√®le)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    tflite_model = converter.convert()

    with open(NOM_TFLITE, 'wb') as f:
        f.write(tflite_model)

    taille_mb = os.path.getsize(NOM_TFLITE) / 1e6
    print(f"  ‚úÖ Fichier TFLite g√©n√©r√© : {NOM_TFLITE} ({taille_mb:.1f} MB)")

    # ============================================================
    # √âTAPE 6 ‚Äî Validation du mod√®le TFLite
    # ============================================================
    print("\nüîç Validation du mod√®le TFLite...")
    interpreteur = tf.lite.Interpreter(model_path=NOM_TFLITE)
    interpreteur.allocate_tensors()

    infos_entree  = interpreteur.get_input_details()
    infos_sortie  = interpreteur.get_output_details()

    print(f"  Entr√©e  : shape={infos_entree[0]['shape']}  dtype={infos_entree[0]['dtype']}")
    print(f"  Sortie  : shape={infos_sortie[0]['shape']} dtype={infos_sortie[0]['dtype']}")

    # Test d'inf√©rence TFLite
    interpreteur.set_tensor(infos_entree[0]['index'], image_factice.numpy())
    interpreteur.invoke()
    sortie_tflite = interpreteur.get_tensor(infos_sortie[0]['index'])
    print(f"  ‚úÖ Inf√©rence TFLite OK : {sortie_tflite}")

    diff_tflite = np.abs(sortie.numpy() - sortie_tflite).max()
    print(f"  Diff√©rence max PyTorch vs TFLite : {diff_tflite:.6f}")

except ImportError:
    print("\n‚ö†Ô∏è  onnx-tf ou tensorflow non install√©.")
    print("Lance ces commandes d'abord :")
    print("  pip install onnx-tf tensorflow")
    print("\nOu utilise directement le fichier ONNX avec ONNX Runtime sur Android.")

# ============================================================
# R√âSUM√â FINAL
# ============================================================
print("\n" + "="*50)
print("üéØ R√âSUM√â DES FICHIERS G√âN√âR√âS")
print("="*50)

fichiers = [NOM_ONNX, NOM_TFLITE]
for f in fichiers:
    if os.path.exists(f):
        print(f"  ‚úÖ {f} ({os.path.getsize(f) / 1e6:.1f} MB)")
    else:
        print(f"  ‚ùå {f} ‚Äî non g√©n√©r√©")

print("\nüì± PROCHAINE √âTAPE :")
print(f"  Copie '{NOM_TFLITE}' dans le dossier assets/ de ton app Android/React Native")
print("  Utilise react-native-fast-tflite pour l'inf√©rence offline")